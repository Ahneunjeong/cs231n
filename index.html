---
layout: default
---

<div>

  스탠포드 CS231n 강의 <a href="http://cs231n.stanford.edu/">CS231n: Convolutional Neural Networks for Visual Recognition</a>에 대한 강의노트의 한글 번역 프로젝트입니다.
  <br>
  질문/논의거리/이슈 등은 <a href="mailto:team.aikorea@gmail.com">AI Korea 이메일</a>로 연락주시거나, <a href="https://github.com/aikorea/cs231n.github.io">GitHub 레포지토리</a>에 pull request, 또는 이슈를 열어주세요.
  <br>
  We encourage the use of the <a href="https://hypothes.is/">hypothes.is</a> extension to annote comments and discuss these notes inline.
</div>

<div class="home">

  <div class="materials-wrap">
    <div class="module-header">
      <a href="/glossary/">Glossary</a>
    </div>

    <div class="module-header">Winter 2016 Assignments</div>

    <div class="materials-item">
      <a href="assignments2016/assignment1/">
        Assignment #1: Image Classification, kNN, SVM, Softmax, Neural Network
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2016/assignment2/">
        Assignment #2: Fully-Connected Nets, Batch Normalization, Dropout,
        Convolutional Nets
      </a>
    </div>

    <div class="materials-item">
      <a href="assignments2016/assignment3/">
        Assignment #3: Recurrent Neural Networks, Image Captioning,
        Image Gradients, DeepDream
      </a>
    </div>

    <!--
    <div class="module-header">Winter 2015 Assignments</div>

    <div class="materials-item">
      <a href="assignment1/">
        Assignment #1: Image Classification, kNN, SVM, Softmax
      </a>
    </div>

    <div class="materials-item">
      <a href="assignment2/">
        Assignment #2: Neural Networks, ConvNets I
      </a>
    </div>

    <div class="materials-item">
      <a href="assignment3/">
        Assignment #3: ConvNets II, Transfer Learning, Visualization
      </a>
    </div>
  -->

    <div class="module-header">Module 0: Preparation</div>

    <div class="materials-item">
      <a href="python-numpy-tutorial/">
        Python / Numpy Tutorial
      </a>
    </div>

    <div class="materials-item">
      <a href="ipython-tutorial/">
        IPython Notebook Tutorial
      </a>
    </div>

    <div class="materials-item">
      <a href="terminal-tutorial/">
        Terminal.com Tutorial
      </a>
    </div>

    <div class="materials-item">
      <a href="aws-tutorial/">
        AWS Tutorial
      </a>
    </div>

	 <!-- hardcoding items here to force a specific order -->
    <div class="module-header">Module 1: 신경망 구조</div>

    <div class="materials-item">
      <a href="classification/">
        영상 분류: 데이터 기반 방법론, k-Nearest Neighbor, train/val/test 구분
      </a>
      <div class="kw">
        L1/L2 거리, hyperparameter 탐색, cross-validation
      </div>
    </div>

    <div class="materials-item">
      <a href="linear-classify/">
         선형 분류: Support Vector Machine, Softmax
      </a>
      <div class="kw">
        parameteric approach, bias trick, hinge loss, cross-entropy loss, L2 regularization, web demo
      </div>
    </div>

    <div class="materials-item">
      <a href="optimization-1/">
        최적화: Stochastic Gradient Descent
      </a>
      <div class="kw">
        optimization landscapes, local search, learning rate, analytic/numerical gradient
      </div>
    </div>

    <div class="materials-item">
      <a href="optimization-2/">
        Backpropagation, Intuition
      </a>
      <div class="kw">
        연쇄 법칙 (chain rule) 해석, real-valued circuits, patterns in gradient flow
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-1/">
          신경망 파트 1: Setting up the Architecture
      </a>
      <div class="kw">
        생물학적 뉴런 모델, activation functions, 신경망 구조, representational power
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-2/">
          신경망 파트 2: 데이터 준비 및 Loss
      </a>
      <div class="kw">
          전처리, weight 초기값 설정, batch normalization, regularization (L2/dropout), loss 함수
      </div>
    </div>

    <div class="materials-item">
      <a href="neural-networks-3/">
        신경망 파트 3: 학습 및 평가
      </a>
      <div class="kw">
        gradient checks, sanity checks, babysitting the learning process, momentum (+nesterov), second-order methods, Adagrad/RMSprop, hyperparameter optimization, model ensembles
      </div>
    </div>

    <!--
    <div class="materials-item">
      <a href="neural-networks-case-study/">
          Putting it together: Minimal Neural Network Case Study
      </a>
      <div class="kw">
        minimal 2D toy data example
      </div>
    </div>
    -->

    <div class="module-header">Module 2: Convolutional Neural Networks</div>

    <div class="materials-item">
      <a href="convolutional-networks/">
        Convolutional Neural Networks: Architectures, Convolution / Pooling Layers
      </a>
      <div class="kw">
          layers, spatial arrangement, layer patterns, layer sizing patterns, AlexNet/ZFNet/VGGNet case studies, computational considerations
      </div>
    </div>

    <div class="materials-item">
      <a href="understanding-cnn/">
        Understanding and Visualizing Convolutional Neural Networks
      </a>
      <div class="kw">
        tSNE embeddings, deconvnets, data gradients, fooling ConvNets, human comparisons
      </div>
    </div>

    <div class="materials-item">
      <a href="transfer-learning/">
        Transfer Learning and Fine-tuning Convolutional Neural Networks
      </a>
    </div>

  </div>
</div>
